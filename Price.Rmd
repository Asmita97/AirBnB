---
title: "Untitled"
author: "Ninad"
date: "5/3/2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```
```{r}
dfX <- read.csv("C:/Users/ninad/Documents/DMPA HW/Frame_for_prediction.csv")

dfX$requires_license<-NULL
dfX$availability_30<-NULL
dfX$availability_60<-NULL
dfX$availability_90<-NULL
#df$city_name<-NULL
#df$is_location_exact<-NULL
#df$host_since<-NULL
dfX$X<-NULL



set.seed(12345)
trainX <- sample(nrow(dfX),0.7*nrow(dfX))
df_trainX <- df[trainX,]
df_testX <- df[-trainX,]


GLM_RegularX <- glm(df_trainX$price~.-high_booking_rate,data=df_trainX)
summary(GLM_RegularX)

```
```{r}
predictprob_test <- predict(GLM_RegularX,newdata = df_testX)

s_predict = sort(predictprob_test)
s_price = sort(df_testX$price)
range01 <- function(x){(x-min(x))/(max(x)-min(x))}



MAE<-mean(abs(predictprob_test-df_testX$price))
MAE

RMSE<-sqrt(mean((predictprob_test-df_testX$price)^2))
RMSE

```

```{r}

#
dfa <- read.csv("C:/Users/ninad/Documents/DMPA HW/Frame_for_prediction.csv")
#
# The data has to be in matrix form for glmnet

dfa$X<-NULL
x=model.matrix(df$price~.-high_booking_rate,dfa)[,-1]
y=dfa$price

library(glmnet)

# Create a grid of 100 lambda values from 10^-2 to 10^10

grid=10^seq(10,-2,length=100)
# Now create a matrix to hold coefficient values for the different lambdas
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
# The dimension of the coef matrix 
dim(coef(ridge.mod))
## The dimensions are [1]  20 100
# The value of lambda at any position in the grid
ridge.mod$lambda[50]
## In this instance, at 50, [1] 11497.57
# The corresponding coefficients are 
coef(ridge.mod)[,50]
## Predict coefficients at lambda = 50, i.e. a new value not in grid
#predict(ridge.mod,s=50,type="coefficients")[1:20,]
#matplot(log(grid),t(coef(ridge.mod)[-1,]), type = c("l"),pch=1, xlab="log(lambda)",ylab="Coefficients") #plot
##
##+-------------------------------------------------+
#     Validation set approach to selecting lambda
##+-------------------------------------------------+
set.seed(1)
train=sample(nrow(x),0.7*nrow(x))
test=(-train)
y.test=y[test]
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
matplot(log(grid),t(coef(ridge.mod)[-1,]), type = c("l"), pch=1,col = "black", xlab="log(lambda)",ylab="Coefficients")
#
# Now generate predictions for the test data using a lambda value of 4
M = rep(0,100)
for (i in 1:100)
{ 
  w = grid[i]
  ridge.pred=predict(ridge.mod,s=w,newx=x[test,])
  M[i] = mean((ridge.pred-y.test)^2)
  }
# plot(c(1,100),c(80000,200000),type="n", xlab="p",ylab="RMSE")
plot(log(grid),M,type='l',col="blue",xlab="Log(lambda)",ylab="MSE")
bestlam = grid[which.min(M)]
min(M)
bestlam
predict(ridge.mod,type="coefficients",s=bestlam)[1:20,]
mse <- function(xA,xP){(mean((xA-xP)^2))}
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:20,]

y.pred <- predict(out,s=bestlam,newx=x[test,])
sqrt(mse(df_testX$price,y.pred))
#
# Let us compare this with linear regression
fit <- lm(price ~ .-high_booking_rate, data=df_trainX)
summary(fit)
Predicted <- predict(fit)

mse(df_trainX$price,Predicted)
#
PredictedT <- predict(fit,newdata=df_testX)
mse(df_testX$price,PredictedT)
sqrt(mse(df_testX$price,PredictedT))

MAE<-mean(abs(y.pred-df_testX$price))
MAE
#
# So clearly, we have better performance with shrinkage model
#

```

```{r LASSO}
## LASSO
library(glmnet)
#
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)
matplot(log(grid),t(coef(lasso.mod)[-1,]), type = c("l"),pch=1,col = "black", xlab="log(lambda)",ylab="Coefficients")

#
# Now generate predictions for the test data using a lambda value of 4
M = rep(0,100)
for (i in 1:100)
{ 
  w = grid[i]
  lasso.pred=predict(lasso.mod,s=w,newx=x[test,])
  M[i] = mean((lasso.pred-y.test)^2)
  }
# plot(c(1,100),c(80000,300000),type="n", xlab="p",ylab="RMSE")
plot(log(grid),M,type='l',col="blue",xlab="Log(lambda)",ylab="MSE")
bestlam = grid[which.min(M)]
min(M)
bestlam
lasso.coef = predict(lasso.mod,type="coefficients",s=bestlam)[1:20,]
lasso.coef[lasso.coef!=0]

y.pred <- predict(lasso.mod,s=bestlam,newx=x[test,])
sqrt(mse(df_testX$price,y.pred))

out=glmnet(x,y,alpha=1)
lasso.coef2 = predict(out,type="coefficients",s=bestlam)[1:20,]
lasso.coef2[lasso.coef2!=0]

MAE<-mean(abs(y.pred-df_testX$price))
MAE

```

```{r K-fold}



#+--------------------------------------------------------------------+
#+      Using K-fold cross-validation                                 +
#+--------------------------------------------------------------------+
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)
##
bestlam=cv.out$lambda.min
bestlam
## [1] 211.7416
ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])
mean((ridge.pred-y.test)^2)
## [1] 96015.51
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:20,]
```




```{r}

tree.price=tree(price~.-high_booking_rate,data=df_trainX)
summary(tree.price)
plot(tree.price)
text(tree.price,pretty=0)
tree.pred=predict(tree.price,df_testX)

s_predict = sort(tree.pred)
s_price = sort(df_testX$price)
range01 <- function(x){(x-min(x))/(max(x)-min(x))}



RMSE<-sqrt(mean((s_price-s_predict)^2))
RMSE

MAE<- mean(abs(s_price-s_predict))
MAE


```
```{r}

cv.regression=cv.tree(tree.price)
plot(cv.regression$size,cv.regression$dev,type='b')
prune.regression<-prune.tree(tree.price,best = 8)
plot(prune.regression)
text(prune.regression,pretty=0)


predicted_price<-predict(prune.regression,df_testX)

RMSE<-sqrt(mean((predicted_price-df_testX$price)^2))
RMSE

MAE<- mean(abs(predicted_price-df_testX$price))
MAE


```
```{r}

randomforest_model=randomForest(price ~.-high_booking_rate,data=df,subset=train,mtry=6,importance=TRUE,na.action=na.roughfix)

#randomforest_model
yhat.bag = predict(randomforest_model,newdata=df_testX)
randomforest.test=df_testX$price

RMSE<-sqrt(mean((predicted_price-randomforest.test)^2))
RMSE
```